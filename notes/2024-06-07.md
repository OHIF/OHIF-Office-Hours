# OHIF Office Hours Notes 2024-07-06

## Q & A

Attendees: 14

Discussed:


üß¨ **Regarding the one-click segmentation that will be available in December, what is the algorithm based on? Is there a paper reference?**

A: Unfortunately we can't share details about this right now. It works fairly well is all we can really tell you. CT tumours are tricky, but the design is a general framework which can be used for GPU ML segmentation.

---

üñ•Ô∏è **Regarding metadata api call in arm64 architecture i have tried but I am stuck there**

A: What issue are you seeing?

---

üî¢ **Currently when you do a 3D or MPR in a study with 2 or more available series, it will pick the first one in the series list, even if you ask to do the 3D from the other series, if both have the same values for the restrictions. Would it make sense to open the 3D from the active series instead (blue border)?**

A: It seems to work, but maybe your steps are different. Try it from the master branch, seems to be ok now.

---

üîó **Here's a url that points the viewer to an anonymized dicomjson US modality dicom. https://viewer.ohif.org/viewer/dicomjson?url=https%3A%2F%2Fxserver-nikki-staging.azurewebsites.net%2Fapi%2Fohif%2Fdicomjson%2Fstudies%2F149698.json all frames except the first load forever. the dicom itself works fine if loaded into viewer through https://viewer.ohif.org/local Is there a datasource in the viewer that can parse dicoms from web without needing json metadata? We noticed this PR: https://github.com/OHIF/Viewers/pull/3935. Is there any guidance on how we could impl. This?**

A: There is also the issue https://github.com/OHIF/Viewers/issues/4204
Where the data all comes from a WADO RS.
The PR 3935 needs some redoing to work properly

extensions/default/src/DicomJSONDataSource/index.js
OHIF is fast because we launch first on a metadata file, and then only load images as needed. If there isn't enough metadata available to render, then it will take a long time to startup because it can't do any grouping or setup initially without loading every single file.
Having a QIDO at the instance level is kind of intermediate in that it can load some information about the organization, but maybe not enough to really hang the series properly.

The job of the data sources is to get the metadata and image data. This can be done by reading the files and parsing out the metadata and image data. You want a mix of what local and dicom json data sources are doing.

Have you considered running Static DICOMweb on your data to local files and just running against the output of that?

https://github.com/RadicalImaging/static-dicomweb 

---

üì± **Android rendering failed on larger data, CR with row & column (0028,0010) : 3480 && (0028,0011) : 4240, it failed to render & console it shows warning, WebGL: INVALID_VALUE: textIamge2D: width or height out of range Do you have any work around? Or any suggestion?**

A: Try CPU rendering (this was tried and seems to have issues)
Look at webglreport.com?v=2
Try the int16 with useNorm16Texture (already there)
Could you try the cornerstonejs cpu rendering example on your device - if that fails, please create an issue for us in CS3D.

---

üñºÔ∏è **Sometimes when doing 3D or MPR the series will end up will more or less frames than the original. Just wanted some info about why that sometimes happens, thank you!**

A: This is about the orientation that this is in - if the data is oblique, then if you show it in axial, then you end up with more slices because some slices are partial. There is a plan to add oblique_axial, oblique_sagittal, oblique_coronal

Try changing the hanging protocol and change your 'axial' to 'acquisition' in cornerstone/‚Ä¶/mpr.ts

---

üîß **We have set up a custom config function for a slice location overlay. In order for this to work I needed to modify CustomViewportOverlay.tsx to ensure an instance (metadata) is passed to the function. There are two issues here: Even in Axial viewport or Basic Viewer the instance doesn't seem to be passed to the config function. For Sagittal and Coronal viewports I need the config function to have access to the first instance so that it can use the Pixel Spacing and Image Position Patient (we assume both are consistent across all instances) My current fix in CustomViewportOverlay.tsx is specific to my team's needs so I'm interested in a solution that can either have all the code be in the custom config function or guidance on a more generalized solution in CustomViewportOverlay.tsx**

A: A solution would be to pass the displaySetService to the _getViewportInstances function in CustomizableViewportOverlay.tsx and utilize the viewportData to get the displaySet, then from the displaySet you can retrieve the instances array and get the current instance by doing instances[currentImageIdIndex]

```typescript
const displaySet = getDisplaySet(viewportData);
const { instances, instance } = displaySet;
const imageIdIndex = viewport.getImageIdIndex();
const currentInstance = instances[imageIdIndex];
```

----

üîç Did you have the time/capacity to check the pull request related to threshold optional center and threshold area? https://github.com/cornerstonejs/cornerstone3D/pull/1267

A: Haven't taken a look yet, will try to look at that shortly.

--- 

üóÑÔ∏è Can we jump to different segments on different segmentations at the same time? Viewport 1: Segmentation 1 Viewport 2: Segmentation 2 Viewport 3: Segmentation 3 We need to highlight a segment on all viewports, is this possible?

A: In the existing UI, no it only goes to the active one. However, you should be able to write a custom command for that. See SegmentationService.jumpToSegmentCenter, and will probably need to overwrite onSegmentClick.
See the tmtv mode as to how the segmentation panel overrides the onSegmentAdd using the customization service.
Overriding that function, you can then implement your custom logic.
