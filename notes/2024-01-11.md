# OHIF Office Hours Notes 204-01-11


## Q & A

Attendees: 10

### Rendering float64 pixel values: We wish to display 2 separate segmentations on the derived volume. The second segmentation’s scalar data has values in decimal numbers up to 20 digits, which we store as Float 64. We wish to preserve this data visually as highly nuanced colors when rendering.

**We’re currently using the WADO image loader, which converts the pixel data to integers for the rendering purposes (https://github.com/cornerstonejs/cornerstoneWADOImageLoader/blob/da4c03933b4b6f634c59614a6aa1a479980f2968/src/imageLoader/createImage.js#L18 ), but we’re planning to migrate to the DICOM Image Loader which to our knowledge should support floats.

Could you please advise us - is it possible to render Float 64 with the DICOM Image Loader? If not, then Float 32? Maybe there are examples on how to achieve this? Thank you very much!
**

A: WebGL does not have native support for 64 bit, however, take a look at the gl-matrix code for Float64Array

https://github.com/Kitware/vtk-js/pull/1796/files
Can also start a discussion with the VTK group on what to do here.

What mapping are you planning on using for 64 bit -> integer pixel values?

Most likely your network was trained on 32 bit 
https://pytorch.org/docs/stable/notes/numerical_accuracy.html

Consider doing a step to convert the float64 to some sort of float32 using your mapping to decide on which sections of the image range are of interest to you.


cornerstoneDICOMImageLoader.external.cornerstone = cornerstone;
  cornerstoneDICOMImageLoader.external.dicomParser = dicomParser;
  cornerstoneDICOMImageLoader.configure({
    useWebWorkers: true,
    decodeConfig: {
      convertFloatPixelDataToInt: false,
      use16BitDataType: preferSizeOverAccuracy || useNorm16Texture,
    },
  });

--- 

### Q: I’m trying to replicate the crosshair behavior of MPR in Stack Crosshairs such that looking at one series, I can translate the cursor position on the primary image to a position on the secondary image. Almost similar to the reference lines tool. I looked at the reference lines code but I’m having a hard time understanding the math of exactly what is going on to translate from one image position in one orientation to another.

A: Want to draw an svg circle around the position on the second image, but not sure how.  Look at referencing cursors for details.

​​https://www.cornerstonejs.org/live-examples/referencecursors

--- 

### Hiding the currently inactive segmentation 

**As mentioned above, we wish to display 2 separate segmentations on the derived volume. Therefore, we have 2 sets of scalar data and 2 segmentation representations on the same volume. We’re using https://www.cornerstonejs.org/docs/concepts/cornerstone-tools/segmentation/active-segmentation/ => setActiveSegmentationRepresentation and setting the renderInactiveSegmentations to false in https://www.cornerstonejs.org/api/tools/namespace/Types#SegmentationRepresentationConfig  to hide the currently inactive segmentation, which works when we’re initially loading the volume, but breaks after the user switches between active and inactive segmentation, leading to both of them being displayed at the same time. 

How can we preserve the inactive segmentation render settings while working on a volume? Thank you!
**

A: This is probably an app level concern where you aren’t setting the values.  OHIF has this, if you set the properties to turn them on/off it works fine.
Have two sets of scalar data, calling create and cache derived volume to create segmentations.  This has two sets of data.
Then switching between the two representations to turn on/off.
Note: Segmentation isn’t the same as representation.  Two representations will share the same configuration and are supposed to represent the same data.  What you need is two segmentations, not two representations (each segmentation will have a unique segmentation UID and representation associated with it)


Try here https://www.cornerstonejs.org/live-examples/stacksegmentation
And add the button to hide inactive segmentation and one to set configuration (colour)

---

### Q: I have one volume (volume1) that can be loaded successfully. I want to define a derived volume (volume2) that will be loaded after volume1 is fully loaded. The metadata of volume2 will be the same as volume1, and the value of each pixel in volume2 will be double of volume1 for each pixel (or random value here in the below code). See code snippets below. 

**What are the main steps that I have missed (or what are the key steps to achieve this)? 
Why do createAndCacheDerivedVolume and createAndCacheVolume return different types of values?
In general, how should we use the return volume returned from createAndCacheVolume()?

    const imageIds = await createImageIdsAndCacheMetaData({...});
  
    const volume1 = await volumeLoader.createAndCacheVolume(volumeId1, {imageIds,});
    const volume2 = await volumeLoader.createAndCacheDerivedVolume(volumeId2, { volumeId: volumeId1 });

    const fillInVolume = (volume:Record<string, any>)=>{
      for(let i=0; i < 480*512*176; i++){
        volume.scalarData[i] = Math.floor(Math.random() * 1500) + 1;
      }
    } 

    const volumeLoadedCallback = ()=>{
      fillInVolume(volume2);
    }   

    // Load T1 MAP volume:
    volume1.load(volumeLoadedCallback);

    // Setup two volume's viewports:
    setVolumesForViewports(renderingEngine, [{ volumeId: volumeId1 }], viewportIds1, true);
    renderingEngine.renderViewports(viewportIds1); 
  
    setVolumesForViewports(renderingEngine, [{ volumeId: volumeId2 }], viewportIds2, true);
    renderingEngine.renderViewports(viewportIds2); 
**


A: You will also need to specify the TypedArray type for the derived volume, and then notify that you have updated things.
Modify the data:

volume.imageData.getPointData().getScalars().setData(newArray)
volume.imageData.modified()

---

### How to manually enable the Crosshairs tool when we switch to MPR hanging protocol, so generally how we can control active tool & toolbar states when we switching hanging protocols?

A: Add an event listener in the hanging protocol to set the tools enabled automatically when you switch.
onProtocolEnter - doesn’t work
Try onViewportDataInitialized

--- 

### It would be great if you can give me some updates about the issue(zoom level is not being reset when switching protocols or changing grid viewports), thanks

https://github.com/OHIF/Viewers/pull/3889

--- 

### Hey, I’m entirely new to OHIF and I was just wondering why measurements weren’t tracked in the sagittal and coronal viewports when in MPR view mode?

A: The SR format we use doesn’t include all the changes for 3d right now
Look at PanelMeasurementTable, TrackingPanelMeasurementTable to include the 3d measurements.
At least a months worth of work to get all the issues fixed.  Need to figure out how to navigate to images, deal with not having an image ID in the data, how to store to the output format, all the conversions for every type

--- 

### We are looking for the interpolation function that is used for increasing the Slab Thickness, and particularly average blend mode, in OHIF, so that we can implement it the same way in the back-end, when running inference for mesothelioma model. My research shows that it comes from VTK.js (and VTK in general). If you have more information about the implementation or can share some related links it will be very appreciated.


A: If you really need the exact same pixels, then I would suggest running a browser internally and exporting the pixels as displayed in CS3D.  If you just need general information about it, then we can talk next week if you add your question again.

The interpolation happens in GPU, it is linear interpolation, So you can use any interpolation utility like ITK, SITK, etc. to interpolate 


---

### What are some resources for reading to know OHIF better?

A: Goto docs.ohif.org, and cornerstonejs.org docs page
Cornerstone is the engine - renders, tools, segmentation, annotations
Packages are core for main viewing, tools for annotations, dicomImageLoader for actually loading data.
OHIF is a separate application which uses CS3D (cornerstone 3d) to combine viewports using react to load/display/save and combine multiple viewports for displaying
