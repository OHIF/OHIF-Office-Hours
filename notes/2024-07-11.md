# OHIF Office Hours Notes 2024-07-27

## Q & A

Attendees: 21

Discussed:

Output 1: Full questions and answers

üîç **hello OHIF community members - I was wondering the easiest way to remove the "INVESTIGATIONAL USE ONLY" text in the top right of the OHIF toolbar. I am aware there is an investigationalUseDialog config var but I was unsure if the dialog is different from the text in the top right? Apologies for the simplistic question, but it is important for our company, we are in veterinary medicine and the text is an eyesore and not relevant to our use case. Thank you so much for your help!**

A: In older versions of OHIF, you can use CSS to hide the banner. In current versions, it is a banner at the bottom controlled by an app config setting.

investigationalUseDialog: This should contain an object with option value, it can be either always which always shows the dialog once per session, never which never shows the dialog, or configure which shows the dialog once and won't show it again until a set number of days defined by the user, if it's set to configure, you are required to add an additional property days which is the number of days to wait before showing the dialog again.

---

üåê **I hope this message finds you well. I have two questions I'd like to ask: 1. Could you please share any plans for implementing WebGPU? 2. Could you kindly share any strategies or measures you have for reducing memory usage?**

A: There are some toolings around WebGPU for some things in CS3D such as growcut. This will be available around November. For the rendering side of things, we don't have the capacity to render in WebGPU, but vtk.js, the library we are using, is slowly working on their webgpu support. You could ask them how they are proceeding on that.

For reducing memory usage, look at the technical faq on how to handle large volumes.
There is also a newer memory allocator allowing allocation up to 4 gb.

https://docs.ohif.org/faq/technical#how-do-i-handle-large-volumes-for-mpr-and-volume-rendering

---

üìú **When it comes to loading dicom SR, are we able to pass them as instances in a DicomJson response (https://docs.ohif.org/configuration/datasources/dicom-json/#dicom-json-sample)? If yes, is there an example anywhere for how nested SR data structures (e.g. ContentSequence) should be serialized for the dicomjson data source?**

A: See the technical FAQ on the minimum amount of metadata required. For SR there is a lot data required. Probably the script that is used doesn't extract the right dataset. If the script doesn't, please create a PR to update the script with the required data.

https://docs.ohif.org/faq/technical#what-are-the-list-of-required-metadata-for-the-ohif-viewer-to-work 

---

üéöÔ∏è **How does the stage selection in hanging protocols work? Can it automatically select a stage based on the number of prior studies?**

A: It goes through all of the stages and check their requirements, there is a set of flags (how many viewports have to filled for a given stage to be valid) 

There are three states:
It can be inactive -> don't have enough viewports to be filled, an RCC view for mamo hanging protocol and there is no right breast images then that stage will be completely inactive
It can be shown (not shown by default) it will show something , the 2x2 mode in mnGrid is not active unless there are 4 image containing series, but still you can go to it 
Fully active

extensions/default/src/hangingprotocols/hpMNGrid.ts

stageActivation: {
     enabled: {
      minViewportsMatched: 4,
    },
},

For Hotkeys

platform/app/public/config/default.js

platform/core/src/defaults/hotkeyBindings.js

You can modify the hotkeys for stage navigation in your config

---

‚è±Ô∏è **I'm curious if you experienced a delay in the metadata request load time when using the DCM4CHEE server. Sometimes, it takes 5 up to 30-40 seconds. Do you possibly have a solution or advice for optimizing it? On your AWS deployment it's instant.**

A: You can put it in a NginX wrapper and enable cache inside it

Or use varnish instead of NginX which has cache

https://varnish-cache.org/

Or use static dicom web which becomes much faster 

https://github.com/RadicalImaging/static-dicomweb

---

üì∑ **I have a question on the concept of the camera, viewplane, & viewup. In 'renderAnnotation' I am having an issue with filterInteractableAnnotationsForElement. ViewPlane is -0,-0,-1 in the annotations The first time through renderAnnotation, all the annotations pass. Second time through the annotations fail: Failing on line 801 in Viewport.js if (viewPlaneNormal &&!isEqual(viewPlaneNormal, camera.viewPlaneNormal) && !isEqual(vec3.negate(camera.viewPlaneNormal, camera.viewPlaneNormal), viewPlaneNormal)) { return options?.withOrientation === true; The camera.viewPlaneNormal has changed to : 0, 1, 0 I see in _calculateCachedStats const canvasCoordinates = points.map((p) => viewport.worldToCanvas(p)) [-42691.15844155844, 250.28571428571428,] let viewport = this.renderingEngine.getViewport(this.viewportId);**

A: When you create the annotations, since you are using the viewport viewReference, you need to wait until the viewport has rendered an image initially. If you add it too soon, it is still rendering/setting up the initial camera, and the metadata returned from getViewReference will be invalid.

https://www.cornerstonejs.org/live-examples/dynamicallyaddannotations
https://github.com/cornerstonejs/cornerstone3D/blob/edba9e4d70dfeb5cad1af645b8a27e0a081f4801/packages/tools/examples/dynamicallyAddAnnotations/index.ts

```typescript
if (type === 'image') {
    // convert image coords to world coords
    start = utilities.imageToWorldCoords(viewport.getCurrentImageId(), <
      Types.Point2
    >[...start]);
    end = utilities.imageToWorldCoords(viewport.getCurrentImageId(), <
      Types.Point2
    >[...end]);
  } else if (type === 'canvas') {
    // convert canvas coords to world coords
    start = viewport.canvasToWorld(<Types.Point2>[...start]);
    end = viewport.canvasToWorld(<Types.Point2>[...end]);
  }

  cornerstoneTools.utilities.annotationHydration(viewport, 'Length', [
    start as Types.Point3,
    end as Types.Point3,
  ]);
```
---

üîç **Q: When using OHIF script from .scripts(convertDicomToJson.js) , it generates the following dicomJson This causes OHIF to not show Patient Name, if set as "PatientName":"Jane Doe" . It is visible in v3.7 but not v3.8. https://viewer.ohif.org/viewer/dicomjson?url=https://ohif-dicom-json-example.s3.amazonaws.com/LIDC-IDRI-0001.json Should the script (convertDicomToJson) be updated ? And a possible bug in 3.8 ?**

A: Search for Alphabetic in the code, you should find that somewhere the code is referencing the wrong element/value field. Please file a bug for us.

---

Ôøºüîç Q: **In Ohif v2 Patient name & PR not visible using the dicomJson generated from the v3 .scripts , but is visible after we remove the following key - SeriesInstanceUID in instance.metadata obj Also OHIF v2, does not pick up the Patient Name even if it is defined. Is this the expected behavior ? or a bug ?**

A: V2 is deprecated at this point and there are not many fixes. Might be a bug but it isn't likely that it will get fixed.


---

Q: üîó **Where is the data from "yarn run cli link-mode ‚Ä¶" stored? I have an old mode that no longer exists yet it keeps getting added to the plugin init javascript. I've grepped and manually removed it from everywhere I can find - is there a global cache somewhere?**

A: platform/app/pluginConfig.json

---

Q: üîí I have a backend server that exposes DICOM Web APIs protected via JWT Auth. I want to know what is the best way to add the Bearer Token Auth header in the requests sent by the OHIF frontend. Ideally, the user will login and the tokens will go into the Combined Context. Then, we can add it to the requests being made? If I can do this in the proper way, I would love to make a PR and contribute ‚Ä¶ I see that the userAuthenticationService has some TODOs that are yet to be implemented. Thank you in advance.

A: This is already implemented in the front end for the standard OAuth authentication flow. Note you need to implement v2.0 because of changes in the browser where 3rd party cookies are disappearing soon. (OAuth 2 with pkce)
You can add a bearer token using a redirect URL (as a URL parameter 'token'):
https://docs.ohif.org/deployment/authorization#token-based-authentication-in-url
https://oauth.net/2/pkce/
https://docs.ohif.org/deployment/user-account-control

---

üìä Q: The OHIF JSON as a data source ‚Äì how stable is it ? Is the plan to go into a different data source eg DICOMWeb etc recommended ? If so, why ? Unfortunately, the DICOMWeb as a data source has some conflicts with our business objectives, so we would like to use DICOM JSON in the production version for the years to come. Is that a good choice from the OHIF roadmap standpoint? Do you anticipate any problems with the DICOMJson way of doing things?


A: The DICOMJson is non-standard but is fairly easy to implement/manage. It is very likely that there are some things broken for the json that work for DICOMweb. There are also some real performance issues as the files get larger.
Try looking at Static DICOMweb - it has many of the same advantages as DICOMJSon but is standards based and works for reasonably large DICOM studies.
https://github.com/RadicalImaging/static-dicomweb


Limitations of static dicom web
- STOW is present but you need to present a dicom web server correctly, plan is to add that to the cloud deployment of it
- Can't ask for anything that is not in the default output, e.g., instanceMetadata cannot get asked separately from series metadata
- You can't ask for other transfer syntaxes, it is static and it is what is there
- It is easier for client to consume, it compressed up front, and it "saves" the dicom

---

üñºÔ∏è Q: **Is multiframe a requirement from a medical standpoint ? eg one instance having 800 frames resulting in a single instance of 30+ MB. When building DICOMJson for SEGs, every frame gets a new instance object defined in the JSON. Since dicomJson SEG is quite large ~330 MB, which causes nodejs to crash at json.stringify() - when generating using convertDicomToJson.js script . On removing the extra frames , dicomJson is successfully created for SEGs ? Is it safe to proceed this way ? What are the implications of such a change ?**


A: There are known issues with DICOMJson and multiframes, and one of those is the issue you are seeing. The longer term solution is to update the DICOMJson format so that it uses the NumberOfFrames instead.
https://stackoverflow.com/questions/34356012/how-to-increase-nodejs-default-memory

---

üñºÔ∏è **Q: Is it advisable to use iframes for studies? Currently, we are not using the React version. What are the pros and cons of using iframes?**

A: usually we recommend using iframe when there needs to be OHIF embedded in another application.

---

üíª Q: **What are the recommended computer specifications for handling large studies, exceeding 1GB in size, with many frames (500 to 1000+)?**

A: Nothing less than 8 GB, but it is more to what type of gpu is present in the device

---

Q: üîß **is there a means to specify the order in which the AnnotationTools run? For example if I have three tools called FlowerTool, TreesTool, BugsTool. I want to specify that Tree annotations are addressed first, then Flower annotations, finally Bug annotations.**

A: packages/tools/src/utilities/triggerAnnotationRender.ts

Seems like if you sort enabledTools then your issue is solved.

---

Q: üíæ **Does the memory get released once all the frames have been loaded? We have larger studies almost a gigabyte and we have tried to compress the study half of its size. Is there a way we could compress the images without losing the quality?**

A: For volumes, no, because the data is still needed for rendering.
For images, individual images will be thrown away when the memory limit is exceeded. These will be refetched as needed.
Users are using laptops that don't have sufficient specs, and are viewing volumes that are high quality/lots of slices.
Try useNorm16Texture - older laptops don't support it so well, but it reduces memory usage by half. It does cause problems on some systems. This should be fixed when we move to webGPU
https://docs.ohif.org/faq/technical#how-do-i-handle-large-volumes-for-mpr-and-volume-rendering

---

Q: üîç **What's the magic behind requesting a frame even though it's a small study that we get up to 300kb requests each frame?**

A: Take a look at the image/frame response header for what encoding is used - the the preview you can see the encoding of hte image. TYpically image/jls encoded images are about 5:1 compression compared to original/uncompressed data.


---

Q: üß¨ Do you support displaying nifti files or numpy data in the viewer? We are looking to find a way to display AI predictions for SEG/RTSTRUCT along with the ground truth segmentation labels already in the dicom files. We would also like to display dose properly resized/rescaled over the scans as well, so any guidance would be appreciated.

A: We are finalizing the addition of dicom parametric maps which are suited for this use case https://github.com/OHIF/Viewers/pull/4284
